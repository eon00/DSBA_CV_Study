import os
import torch
import numpy as np
import argparse
import pandas as pd
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from resnet import Model  

# Argument ì„¤ì •
parser = argparse.ArgumentParser()
parser.add_argument("--gpu", type=int, default=0, choices=[0, 1], help="Choose GPU (0 or 1)")
parser.add_argument("--pretrained", action="store_true", help="Use pretrained model for inference")
parser.add_argument("--model_path", type=str, required=True, help="Path to the saved model")
args = parser.parse_args()

# GPU ì„¤ì •
if torch.cuda.is_available():
    device = torch.device(f"cuda:{args.gpu}")
    print(f"ğŸ”¹ Using GPU: cuda:{args.gpu}")
else:
    device = torch.device("cpu")
    print("ğŸ”¹ CUDA not available, using CPU")

# ë°ì´í„° ë¡œë“œ (numpy)
data_folder = "../data/data"
test_data = np.load(f"{data_folder}/test_data.npy")  
test_target = np.load(f"{data_folder}/test_target.npy")  

# PyTorch Dataset í´ë˜ìŠ¤ ì •ì˜
class CustomDataset(Dataset):
    def __init__(self, data, targets, transform=None):
        self.data = data
        self.targets = targets
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        image = self.data[idx]  
        label = self.targets[idx]  
        
        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)  

        if self.transform:
            image = self.transform(image)

        return image, torch.tensor(label, dtype=torch.long)

# ë°ì´í„° ë³€í™˜ ì •ì˜
test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])


# Dataset ë° DataLoader ìƒì„±
test_dataset = CustomDataset(test_data, test_target, transform=test_transform)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

# ëª¨ë¸ ë¡œë“œ
print("ğŸ”¹ Loading Model...")
model = Model().resnet50()

# ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
model.load_state_dict(torch.load(args.model_path, map_location=device))
model.to(device)
model.eval()
print(f"âœ… Model loaded from {args.model_path}")

# ğŸ”¹ Inference ì‹œì‘
correct, total = 0, 0
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)
        
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# ìµœì¢… Accuracy ì¶œë ¥
accuracy = 100 * correct / total
print(f"âœ… Test Accuracy: {accuracy:.2f}%")

# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ì €ì¥
df = pd.DataFrame({"True Label": all_labels, "Predicted Label": all_preds})
csv_filename = "inference_results_non_augmentation_True.csv"
df.to_csv(csv_filename, index=False)
print(f"âœ… Inference results saved to '{csv_filename}'")

# ê²°ê³¼ ë°˜í™˜
def get_predictions():
    return df["True Label"].values, df["Predicted Label"].values  # ì‹¤ì œê°’, ì˜ˆì¸¡ê°’ ë°˜í™˜