import argparse
import yaml
import torch
import numpy as np
import pandas as pd
import os


# âœ… Argument Parser ì„¤ì •
parser = argparse.ArgumentParser(description="ViT Inference Script")
parser.add_argument("--config", type=str, default="config.yaml", help="Path to the config file")
args = parser.parse_args()

# âœ… config ë¡œë“œ í•¨ìˆ˜
def load_config(config_path):
    with open(config_path, "r") as file:
        return yaml.safe_load(file)

# âœ… config ë¡œë“œ ë° DEVICE ì„¤ì •
config = load_config(args.config)

# âœ… DEVICE ì„¤ì • (ê¸°ë³¸ê°’: CPU -> GPU ê°€ëŠ¥ ì‹œ ì„¤ì •)
if torch.cuda.is_available():
    device_id = torch.cuda.current_device()  # í˜„ì¬ GPU ID ê°€ì ¸ì˜¤ê¸°
    DEVICE = torch.device(f"cuda:{device_id}")
    print(f"Using GPU: cuda:{device_id}")
else:
    DEVICE = torch.device("cpu")
    print("CUDA is not available. Using CPU.")

# âœ… ë°ì´í„° ë¡œë” & ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
from dataloader import get_dataloaders
from models import get_model
from transformers import Trainer, TrainingArguments

# âœ… ëª¨ë¸ ë¡œë“œ
model = get_model(config, DEVICE, is_train=False)  # Inferenceì—ì„œëŠ” ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜´
model.eval()

# âœ… ë°ì´í„° ë¡œë“œ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ë§Œ ì‚¬ìš©)
_, test_loader = get_dataloaders(config)

# âœ… ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
output_dir = config["inference"].get("output_path", "results")  # âœ… ì €ì¥í•  ë””ë ‰í† ë¦¬ ì„¤ì •
os.makedirs(output_dir, exist_ok=True)  # âœ… ë””ë ‰í† ë¦¬ ì—†ìœ¼ë©´ ìƒì„±

# âœ… Trainer ì„¤ì •
trainer = Trainer(
    model=model,
    args=TrainingArguments(**config["training_args"]),
    eval_dataset=test_loader.dataset
)

# âœ… Inference ì‹¤í–‰
def run_inference():
    print("ğŸ”¹ Running Inference...")
    predictions = trainer.predict(test_loader.dataset).predictions
    predicted_labels = np.argmax(predictions, axis=1)  # âœ… í™•ë¥ ê°’ì—ì„œ ê°€ì¥ ë†’ì€ í´ë˜ìŠ¤ë¡œ ë³€í™˜

    # âœ… ê²°ê³¼ CSV ì €ì¥
    save_results_to_csv(predicted_labels, test_loader.dataset.targets)

# âœ… ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥
def save_results_to_csv(predicted_labels, true_labels):
    df = pd.DataFrame({
        "True Label": true_labels,
        "Predicted Label": predicted_labels
    })
    output_csv_path = f"{output_dir}/inference_results.csv"
    df.to_csv(output_csv_path, index=False)
    print(f"âœ… Inference results saved to {output_csv_path}")

if __name__ == "__main__":
    run_inference()