# huggingface:
#   token: "hf_xxx"  # Hugging Face API Token (필요하면 입력)
device:
  # gpu: 0
  use_cuda: true

  
model: 
  base_model: "google/vit-base-patch16-224"
  num_classes: 10
  pretrained: true


training_args:
  output_dir: "../checkpoints/vit-training-augmentation/pretrained"  # ✅ 체크포인트 저장 경로 (그대로 유지)
  num_train_epochs: 5
  do_eval: true
  per_device_train_batch_size: 32
  per_device_eval_batch_size: 32
  gradient_accumulation_steps: 1
  optim: "adamw_torch"
  learning_rate: 3.0e-5
  weight_decay: 0.01
  logging_dir: "./logs"
  logging_steps: 100
  save_strategy: "epoch"
  evaluation_strategy: "steps"
  save_total_limit: 2  # ✅ 최근 2개 체크포인트만 저장
  seed: 42
  fp16: true


inference:
  batch_size: 32
  model_path: "../saved_model/pretrained/best_vit_augmentation.pth"  # ✅ 변경된 모델 경로
  use_trained_model: false  # ✅ 이 옵션을 추가해야 학습된 모델을 로드함
  output_path: "../results/pretrained_not_finetuning"


data:
  path: "../../data/data"
  image_size: 224
  max_seq_length: 512
  dataset_type: "numpy"  # numpy 형식 데이터 사용

wandb:
  project: "ViT-training"
  entity: "eonn347"
  run_name: "vit-training-experiment-augmentation"

process:
  process_name: "vit-training-augmentation"